{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanhChun/Log-Analyzer-with-NLP-model/blob/main/Logs_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "pGf1AemKJ5QI",
        "outputId": "b685a1e8-4ee9-47dc-8aae-2bcace676db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04c04766-7dbb-4d2f-8607-b8af10815c31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-04c04766-7dbb-4d2f-8607-b8af10815c31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labeled_logs.csv to labeled_logs (2).csv\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZELruEhKV8pR",
        "outputId": "ed67a882-8267-4cdd-b5a4-9db723e71043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các nhãn có trong dữ liệu: ['Normal' 'NOTE - all threads closed'\n",
            " 'NOTE - speaker changes state from On to Off'\n",
            " 'NOTE - speaker changes state from Off to On' 'ERROR - control amplifier'\n",
            " 'WARNING - On disconnect' 'ERROR - start MPD failed'\n",
            " 'ERROR - delete message' 'ERROR - MPD problem' 'ERROR - config SIM, GSM'\n",
            " 'ERROR - invalid checksum' 'ERROR - invalid message size'\n",
            " 'Note - message played done' 'ERROR - message download']\n",
            "Mapping giữa nhãn và số sau khi sửa: {'ERROR - MPD problem': np.int64(0), 'ERROR - config SIM, GSM': np.int64(1), 'ERROR - control amplifier': np.int64(2), 'ERROR - delete message': np.int64(3), 'ERROR - invalid checksum': np.int64(4), 'ERROR - invalid message size': np.int64(5), 'ERROR - message download': np.int64(6), 'ERROR - start MPD failed': np.int64(7), 'NOTE - all threads closed': np.int64(8), 'NOTE - speaker changes state from Off to On': np.int64(9), 'NOTE - speaker changes state from On to Off': np.int64(10), 'Normal': np.int64(11), 'Note - message played done': np.int64(12), 'WARNING - On disconnect': np.int64(13)}\n",
            "Dữ liệu đã được xử lý và lưu thành công!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Đọc file CSV\n",
        "df = pd.read_csv(\"labeled_logs.csv\")\n",
        "\n",
        "# Chuẩn hóa cột \"labels\" (loại bỏ khoảng trắng thừa)\n",
        "df[\"labels\"] = df[\"labels\"].str.strip()\n",
        "\n",
        "# Kiểm tra nhãn trong dữ liệu\n",
        "unique_labels = df[\"labels\"].unique()\n",
        "print(\"Các nhãn có trong dữ liệu:\", unique_labels)\n",
        "\n",
        "# Tìm và sửa lỗi nhãn không đúng\n",
        "for label in unique_labels:\n",
        "    if \"NormalERROR\" in label or \"ERRORNormal\" in label:\n",
        "        print(\"Nhãn có vấn đề:\", label)\n",
        "\n",
        "# Sửa lỗi nhãn bằng cách thay thế tất cả trường hợp lỗi\n",
        "df[\"labels\"] = df[\"labels\"].replace({\n",
        "    \"NormalERROR - SIM, GSM\": \"Normal\"\n",
        "})\n",
        "\n",
        "# Mã hóa nhãn bằng LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"labels\"])\n",
        "\n",
        "# Kiểm tra ánh xạ sau khi sửa\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Mapping giữa nhãn và số sau khi sửa:\", label_mapping)\n",
        "\n",
        "# Lưu LabelEncoder để sử dụng sau này\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Xuất file CSV đã xử lý\n",
        "df.to_csv(\"processed_logs.csv\", index=False)\n",
        "\n",
        "print(\"Dữ liệu đã được xử lý và lưu thành công!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSjqV8KeMcRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96749e31-088b-4b4f-909e-5bcb205be06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danh sách nhãn sau khi làm sạch: ['Normal' 'NOTE - all threads closed'\n",
            " 'NOTE - speaker changes state from On to Off'\n",
            " 'NOTE - speaker changes state from Off to On' 'ERROR - control amplifier'\n",
            " 'WARNING - On disconnect' 'ERROR - start MPD failed'\n",
            " 'ERROR - delete message' 'ERROR - MPD problem' 'ERROR - config SIM, GSM'\n",
            " 'ERROR - invalid checksum' 'ERROR - invalid message size'\n",
            " 'Note - message played done' 'ERROR - message download']\n"
          ]
        }
      ],
      "source": [
        "# Sửa các nhãn có vấn đề\n",
        "df[\"labels\"] = df[\"labels\"].replace({\"NormalERROR - SIM, GSM\": \"Normal\"})  # Hoặc sửa theo đúng nhãn mong muốn\n",
        "\n",
        "# Đảm bảo tất cả nhãn đều hợp lệ\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Kiểm tra lại\n",
        "print(\"Danh sách nhãn sau khi làm sạch:\", df[\"labels\"].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF3pu48jliwf"
      },
      "source": [
        "**TOKENIZE DỮ LIỆU VÀ CHIA DỮ LIỆU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuIcp93SWQMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa87c37-8592-45a4-f0a3-681c9fa1802b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Tên các cột trong DataFrame: ['logs', 'labels', 'label_encoded']\n",
            "Tổng số mẫu: 4820\n",
            "Số mẫu train: 3856\n",
            "Số mẫu test: 482\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện cần thiết\n",
        "!pip install torch transformers datasets scikit-learn pandas\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Đọc file CSV\n",
        "df = pd.read_csv(\"processed_logs.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# Kiểm tra các cột có trong DataFrame\n",
        "print(\"Tên các cột trong DataFrame:\", df.columns.tolist())\n",
        "\n",
        "# Kiểm tra nếu 'logs' không tồn tại thì báo lỗi\n",
        "if \"logs\" not in df.columns:\n",
        "    raise ValueError(\"Cột 'logs' không tồn tại trong file CSV! Kiểm tra lại tên cột.\")\n",
        "\n",
        "# Loại bỏ các dòng có giá trị NaN trong logs\n",
        "df = df.dropna(subset=[\"logs\"])\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_length = 128  # Độ dài tối đa của chuỗi token\n",
        "\n",
        "tokens = tokenizer(\n",
        "    df[\"logs\"].tolist(),  # Chuyển logs thành danh sách trước khi token hóa\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=max_length,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Dataset PyTorch\n",
        "class LogDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# Kiểm tra xem 'label_encoded' có tồn tại không\n",
        "if \"label_encoded\" not in df.columns:\n",
        "    raise ValueError(\"Cột 'label_encoded' không tồn tại! Kiểm tra lại dữ liệu.\")\n",
        "\n",
        "# Chuyển nhãn thành tensor\n",
        "labels = torch.tensor(df[\"label_encoded\"].values, dtype=torch.long)\n",
        "\n",
        "# Tạo dataset\n",
        "dataset = LogDataset(tokens, labels)\n",
        "\n",
        "# Chia tập train/test (80/20)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Tạo DataLoader\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # Create val_loader\n",
        "\n",
        "\n",
        "# Kiểm tra số lượng mẫu\n",
        "print(f\"Tổng số mẫu: {len(dataset)}\")\n",
        "print(f\"Số mẫu train: {len(train_dataset)}\")\n",
        "print(f\"Số mẫu test: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMvPVN_gXVNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f227f8a3-24e2-4ee3-a96c-17cfd97aa80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0tThPIldCV"
      },
      "source": [
        "**CÀI ĐẶT CUDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z45CVRPdXYSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95a32e1-a613-463a-ce63-871b2ea92e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Kiểm tra GPU (nếu có)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n",
        "# Khởi tạo mô hình với DistilBERT\n",
        "num_labels = len(df[\"label_encoded\"].unique())  # Số nhãn đầu ra\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
        "model.to(device)\n",
        "\n",
        "# Định nghĩa hàm mất mát và optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZDlF4YJPBYj"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_masks[idx],\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)  # Dòng này gây cảnh báo\n",
        "        }\n",
        "\n",
        "        # Kiểm tra nếu labels chưa là tensor, thì chuyển đổi\n",
        "        label = self.labels[idx]\n",
        "        if not isinstance(label, torch.Tensor):\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        item[\"labels\"] = label  # Gán nhãn vào item\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbhGQ_dElZqR"
      },
      "source": [
        "**CẤU HÌNH TRAIN VÀ TIẾN HÀNH TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4WTjer6OMeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b60bc71-a4be-495a-d8f8-3a5209815b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Kiểm tra train_loader có tồn tại không\n",
        "assert 'train_loader' in globals(), \"train_loader chưa được khởi tạo!\"\n",
        "\n",
        "# Kiểm tra batch có đủ input_ids, attention_mask, labels\n",
        "sample_batch = next(iter(train_loader))\n",
        "assert \"input_ids\" in sample_batch and \"attention_mask\" in sample_batch and \"labels\" in sample_batch, \\\n",
        "    \"Batch không chứa đủ input_ids, attention_mask, labels!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2uBZMmeXgAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15694ff2-ea4c-418c-8010-b2c745f16e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/3:   0%|          | 0/241 [00:00<?, ?it/s]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:   5%|▍         | 11/241 [00:01<00:39,  5.87it/s, loss=1.21]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  17%|█▋        | 40/241 [00:06<00:36,  5.58it/s, loss=1.43]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  23%|██▎       | 56/241 [00:09<00:32,  5.71it/s, loss=0.649]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  31%|███       | 74/241 [00:12<00:28,  5.82it/s, loss=0.296]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  37%|███▋      | 90/241 [00:15<00:26,  5.68it/s, loss=0.132]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  42%|████▏     | 101/241 [00:17<00:25,  5.46it/s, loss=0.0783]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  49%|████▉     | 119/241 [00:20<00:21,  5.68it/s, loss=0.0524]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  56%|█████▌    | 134/241 [00:23<00:19,  5.61it/s, loss=0.0385]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  61%|██████    | 146/241 [00:25<00:16,  5.60it/s, loss=0.0376]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  68%|██████▊   | 163/241 [00:28<00:13,  5.61it/s, loss=0.0139]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  72%|███████▏  | 174/241 [00:30<00:11,  5.61it/s, loss=0.0178]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  78%|███████▊  | 187/241 [00:32<00:09,  5.70it/s, loss=0.535]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  85%|████████▍ | 204/241 [00:35<00:06,  5.77it/s, loss=0.0124]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  92%|█████████▏| 221/241 [00:38<00:03,  5.80it/s, loss=0.0134]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3:  99%|█████████▉| 239/241 [00:41<00:00,  5.79it/s, loss=0.0107]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3: 100%|██████████| 241/241 [00:42<00:00,  5.73it/s, loss=0.00831]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3:\n",
            "Train Loss: 0.4268\n",
            "Val Loss: 0.0220, Val Accuracy: 99.5851%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3:   2%|▏         | 5/241 [00:00<00:42,  5.62it/s, loss=0.00921]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:   7%|▋         | 18/241 [00:03<00:38,  5.76it/s, loss=0.00854]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  14%|█▍        | 34/241 [00:05<00:36,  5.70it/s, loss=0.00801]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  20%|█▉        | 47/241 [00:08<00:33,  5.75it/s, loss=0.00968]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  27%|██▋       | 64/241 [00:11<00:31,  5.64it/s, loss=0.00793]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  34%|███▍      | 82/241 [00:14<00:28,  5.60it/s, loss=0.00537]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  40%|████      | 97/241 [00:16<00:26,  5.38it/s, loss=0.00556]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  47%|████▋     | 113/241 [00:19<00:23,  5.53it/s, loss=0.00774]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  52%|█████▏    | 125/241 [00:21<00:20,  5.68it/s, loss=0.00415]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  56%|█████▌    | 135/241 [00:23<00:19,  5.36it/s, loss=0.00241]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  61%|██████▏   | 148/241 [00:26<00:16,  5.48it/s, loss=0.00511]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  68%|██████▊   | 163/241 [00:28<00:14,  5.50it/s, loss=0.0033]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  73%|███████▎  | 175/241 [00:30<00:11,  5.81it/s, loss=0.00295]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  78%|███████▊  | 188/241 [00:33<00:09,  5.82it/s, loss=0.00481]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  85%|████████▌ | 205/241 [00:35<00:06,  5.84it/s, loss=0.00472]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  90%|████████▉ | 216/241 [00:37<00:04,  5.74it/s, loss=0.00529]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3:  98%|█████████▊| 235/241 [00:40<00:01,  5.82it/s, loss=0.00355]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 2/3: 100%|██████████| 241/241 [00:42<00:00,  5.74it/s, loss=0.00459]\n",
            "<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3:\n",
            "Train Loss: 0.0253\n",
            "Val Loss: 0.0087, Val Accuracy: 99.5851%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3:   7%|▋         | 17/241 [00:02<00:38,  5.83it/s, loss=0.00333]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  13%|█▎        | 31/241 [00:05<00:36,  5.78it/s, loss=0.00308]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  20%|██        | 49/241 [00:08<00:32,  5.85it/s, loss=0.00146]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  26%|██▌       | 62/241 [00:10<00:30,  5.81it/s, loss=0.00348]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  31%|███       | 74/241 [00:12<00:28,  5.80it/s, loss=0.00136]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  38%|███▊      | 92/241 [00:15<00:25,  5.84it/s, loss=0.00225]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  44%|████▍     | 106/241 [00:18<00:23,  5.68it/s, loss=0.00187]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  51%|█████     | 122/241 [00:20<00:20,  5.77it/s, loss=0.00194]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  58%|█████▊    | 139/241 [00:23<00:18,  5.58it/s, loss=0.00171]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  64%|██████▍   | 155/241 [00:26<00:15,  5.57it/s, loss=0.0023]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  72%|███████▏  | 173/241 [00:29<00:11,  5.73it/s, loss=0.00372]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  80%|███████▉  | 192/241 [00:32<00:08,  5.83it/s, loss=0.00886]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  88%|████████▊ | 213/241 [00:36<00:04,  5.80it/s, loss=0.00106]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3:  95%|█████████▌| 230/241 [00:39<00:01,  5.78it/s, loss=0.00126]<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 3/3: 100%|██████████| 241/241 [00:41<00:00,  5.83it/s, loss=0.00219]\n",
            "<ipython-input-25-dba6642a4671>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3:\n",
            "Train Loss: 0.0142\n",
            "Val Loss: 0.0030, Val Accuracy: 100.0000%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # Hiển thị tiến trình huấn luyện\n",
        "\n",
        "# Hàm tính độ chính xác\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Dự đoán nhãn\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Số epoch huấn luyện\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Tính loss & accuracy trên tập train\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Tính loss & accuracy trên tập validation\n",
        "    val_loss, val_accuracy = compute_accuracy(model, val_loader)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4%}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRAaVAAHTamn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f599c1-f215-4b68-9298-40f30262abf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình và tokenizer đã được lưu vào thư mục: distilbert_log_classifier\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Tạo thư mục lưu mô hình\n",
        "model_dir = \"distilbert_log_classifier\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Lưu mô hình\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "print(f\" Mô hình và tokenizer đã được lưu vào thư mục: {model_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMYg6KYfTf-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fe4716-0209-475c-ba2e-49d80b3a95f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LabelEncoder đã được lưu tại: distilbert_log_classifier/label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Lưu LabelEncoder\n",
        "label_encoder_path = os.path.join(model_dir, \"label_encoder.pkl\")\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(f\" LabelEncoder đã được lưu tại: {label_encoder_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxuvSubMThdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab81966-ca8b-4d69-a9fa-39433ec4ccb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Danh sách tệp đã lưu:\n",
            "['model.safetensors', 'vocab.txt', 'tokenizer_config.json', 'special_tokens_map.json', 'config.json', 'label_encoder.pkl']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\" Danh sách tệp đã lưu:\")\n",
        "print(os.listdir(model_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX20g4jBUHbG"
      },
      "source": [
        "**TẢI LẠI MÔ HÌNH VÀ TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie7Cx6BXTkoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a09697e-4bec-4304-e647-812f4ae4e86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình và tokenizer đã được tải thành công!\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "# Định nghĩa đường dẫn mô hình đã lưu\n",
        "model_dir = \"distilbert_log_classifier\"\n",
        "\n",
        "# Tải mô hình & tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Đưa mô hình lên GPU nếu có\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\" Mô hình và tokenizer đã được tải thành công!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBWyTX12UTNW"
      },
      "source": [
        "**TẢI LẠI LABEL ENCODER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhkFZjTCTvzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744297e9-07e3-496f-b40c-3615bbf0f7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LabelEncoder đã được tải thành công!\n"
          ]
        }
      ],
      "source": [
        "# Tải LabelEncoder để giải mã nhãn\n",
        "label_encoder_path = f\"{model_dir}/label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "print(\" LabelEncoder đã được tải thành công!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff8txBcxUbDf"
      },
      "source": [
        "**KIỂM TRA MÔ HÌNH VỚI 1 LOG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HEc3kZAT1Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3ad633-c243-4023-b986-51c5c747d91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Log: System overheating detected. Close all threads in 5 seconds.\n",
            "Cảnh báo dự đoán: Normal\n"
          ]
        }
      ],
      "source": [
        "log_message = \"System overheating detected. Close all threads in 5 seconds.\"\n",
        "# Tokenize dữ liệu\n",
        "inputs = tokenizer(log_message, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}  # Đưa lên GPU nếu có\n",
        "\n",
        "# Thực hiện suy luận\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "\n",
        "# Giải mã nhãn từ số thành nội dung cảnh báo\n",
        "decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "print(f\" Log: {log_message}\")\n",
        "print(f\"Cảnh báo dự đoán: {decoded_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"fine_tuned_model\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels),\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"fine_tunned_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "fnCErWbL8_o_",
        "outputId": "792fafe0-e5d8-4823-e09a-3d7c0551d9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdlYWmOUgv3"
      },
      "source": [
        "**KIỂM TRA MÔ HÌNH VỚI NHIỀU LOG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2yDUbiOT7Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d08ed8-69cb-488b-8f93-50817b6c284a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Log: Temperature sensor failure detected.\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n",
            " Log: Unauthorized access attempt detected.\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n",
            " Log: Battery voltage critically low.\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n",
            " Log: Network connection lost. Reconnecting...\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "log_samples = [\n",
        "    \"Temperature sensor failure detected.\",\n",
        "    \"Unauthorized access attempt detected.\",\n",
        "    \"Battery voltage critically low.\",\n",
        "    \"Network connection lost. Reconnecting...\"\n",
        "]\n",
        "\n",
        "for log in log_samples:\n",
        "    inputs = tokenizer(log, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Đưa lên GPU nếu có\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "\n",
        "    decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "    print(f\" Log: {log}\")\n",
        "    print(f\" Cảnh báo dự đoán: {decoded_label}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8SiSUyTB6Ok"
      },
      "source": [
        "**LƯU LẠI MÔ HÌNH TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2UPe3Lo_T6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616f348c-948f-489f-ddbc-c95b69aff81f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c3607ce9990>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c3617fd7850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c36062fe6d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c3606e6ff90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c361c2236d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7c3606d76250>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình đã được chuyển sang định dạng TensorFlow và lưu tại: saved_model_distilbert\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFDistilBertForSequenceClassification\n",
        "\n",
        "# Tải lại mô hình từ thư mục đã lưu trước đó\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert_log_classifier\", from_pt=True)\n",
        "\n",
        "# Chuyển mô hình sang định dạng SavedModel (để có saved_model.pb)\n",
        "export_dir = \"saved_model_distilbert\"\n",
        "model.save_pretrained(export_dir, saved_model=True)\n",
        "\n",
        "print(f\" Mô hình đã được chuyển sang định dạng TensorFlow và lưu tại: {export_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHX5_7QgB1v9"
      },
      "source": [
        "**TỐI ƯU MÔ HÌNH**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UUDLBlZH50d"
      },
      "source": [
        "**Convert to TF lite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC-n6m5q7dM_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "436f2f87-3f35-4e9a-fea9-a42b6190596b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-tflite (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-tflite\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'distilbert_qat_int8.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-027b63f51464>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m model_int8 = DistilBertForSequenceClassification.from_pretrained(\n\u001b[1;32m     10\u001b[0m     \"distilbert-base-uncased\", num_labels = 15)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_int8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert_qat_int8.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel_int8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'distilbert_qat_int8.pth'"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets scikit-learn\n",
        "!pip install torch-tflite\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Load mô hình đã quantized\n",
        "model_int8 = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels = 15)\n",
        "model_int8.load_state_dict(torch.load(\"distilbert_qat_int8.pth\"))\n",
        "model_int8.eval()\n",
        "\n",
        "# Chuyển đổi sang TorchScript\n",
        "scripted_model = torch.jit.trace(lambda x, y: model_int8(x, attention_mask = y).logits, (torch.randint(0, 30522, (1, 128)), torch.ones((1, 128), dtype=torch.long)))\n",
        "scripted_model.save(\"distilbert_qat_int8.pt\")\n",
        "\n",
        "# Chuyển sang TFLite\n",
        "import torch_tflite\n",
        "tflite_model = torch_tflite.convert(scripted_model)\n",
        "open(\"distilbert_qat_int8.tflite\", \"wb\").write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WLAAtbVAIV"
      },
      "source": [
        "**CHUYỂN MÔ HÌNH SANG TF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEE0ubzhZjv8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Kiểm tra thư mục đã lưu mô hình\n",
        "export_dir = \"saved_model_distilbert/saved_model\"\n",
        "\n",
        "if os.path.exists(export_dir):\n",
        "    print(\" Mô hình đã lưu thành công!\")\n",
        "    print(f\" Danh sách file trong {export_dir}: {os.listdir(export_dir)}\")\n",
        "else:\n",
        "    print(\" Lưu mô hình thất bại! Hãy kiểm tra lại quá trình lưu mô hình.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxXJKp99dBOJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load mô hình đã huấn luyện\n",
        "model = tf.keras.models.load_model(\"saved_model_distilbert/saved_model/1/\")\n",
        "\n",
        "# Chuyển đổi sang TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_distilbert/saved_model/1/\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Lưu file .tflite\n",
        "with open(\"distilbert_log_classifier.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Chuyển đổi thành công! File đã lưu.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA0PpWHEfCeZ"
      },
      "outputs": [],
      "source": [
        "print(input_details)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_cCyKamccOJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Load tokenizer giống như lúc train\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Load model\n",
        "interpreter = tflite.Interpreter(model_path=\"distilbert_log_classifier.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Lấy thông tin tensor input/output\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Chuyển đổi câu log thành tensor (chỉ lấy token đầu tiên)\n",
        "test_log = \"Close all threads\"\n",
        "tokens = tokenizer.encode(test_log, truncation=True)\n",
        "\n",
        "# Chỉ lấy 1 token đầu tiên để phù hợp shape [1, 1]\n",
        "first_token = tokens[0] if len(tokens) > 0 else 0\n",
        "\n",
        "# Đảm bảo đúng shape [1, 1]\n",
        "input_ids = np.array([[first_token]], dtype=np.int64)\n",
        "attention_mask = np.array([[1]], dtype=np.int64)\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], attention_mask)  # attention mask\n",
        "interpreter.set_tensor(input_details[1]['index'], input_ids)  # input IDs\n",
        "\n",
        "# Chạy mô hình\n",
        "interpreter.invoke()\n",
        "\n",
        "# Lấy kết quả\n",
        "output = interpreter.get_tensor(output_details[0]['index'])\n",
        "predicted_label = np.argmax(output)\n",
        "\n",
        "print(f\"Log: {test_log}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOhU2__CdJms"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPeImvu3dJ26"
      },
      "source": [
        "**XỬ LÝ ĐẦU VÀO MÔ HÌNH CHO QUÁ TRÌNH PTQ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-pjUtaDeZV7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load lại mô hình từ SavedModel\n",
        "model = tf.keras.models.load_model(\"saved_model_distilbert/saved_model/1\", compile=False)\n",
        "\n",
        "# Chuyển mô hình về dạng `tf.function` để cố định input shape\n",
        "@tf.function(input_signature=[\n",
        "    tf.TensorSpec(shape=[1, 128], dtype=tf.int32, name=\"input_ids\"),\n",
        "    tf.TensorSpec(shape=[1, 128], dtype=tf.int32, name=\"attention_mask\"),\n",
        "])\n",
        "def serving_fn(input_ids, attention_mask):\n",
        "    outputs = model({\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
        "    logits = outputs[\"logits\"]  # Truy cập logits từ dictionary\n",
        "    return {\"logits\": tf.identity(logits, name=\"logits\")}  # Đảm bảo output là tf.Tensor\n",
        "\n",
        "# Lưu mô hình mới với input cố định\n",
        "fixed_model_dir = \"saved_model_distilbert_fixed\"\n",
        "tf.saved_model.save(model, fixed_model_dir, signatures={\"serving_default\": serving_fn})\n",
        "\n",
        "print(f\"Mô hình đã lưu với input cố định tại {fixed_model_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQVUDB3nghYc"
      },
      "source": [
        "**THỰC HIỆN PTQ INT8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8uQfzQOeewz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load mô hình đã sửa\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_distilbert_fixed\")\n",
        "\n",
        "# Bật lượng tử hóa trọng số (INT8)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Sử dụng tập dữ liệu đại diện để giúp lượng tử hóa\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(100):\n",
        "        input_ids = np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "        attention_mask = np.ones((1, 128), dtype=np.int32)\n",
        "        yield [input_ids, attention_mask]  # Trả về tuple thay vì dictionary\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "# Cấu hình kiểu dữ liệu đầu vào và đầu ra của mô hình\n",
        "converter.inference_input_type = tf.int8   # Đầu vào INT8\n",
        "converter.inference_output_type = tf.int8  # Đầu ra INT8\n",
        "\n",
        "# Chuyển đổi mô hình sang TFLite\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Lưu mô hình mới\n",
        "with open(\"distilbert_log_classifier_int8.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Chuyển đổi thành công!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc1GrX6cfaRb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load mô hình TFLite INT8\n",
        "interpreter = tf.lite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Lấy thông tin tensor đầu vào & đầu ra\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Thông tin đầu vào:\", input_details)\n",
        "print(\"Thông tin đầu ra:\", output_details)\n",
        "\n",
        "# Tạo dữ liệu test (để nguyên dtype int32)\n",
        "input_ids = np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "attention_mask = np.ones((1, 128), dtype=np.int32)\n",
        "\n",
        "# Đưa dữ liệu vào mô hình (KHÔNG CHUYỂN SANG int8)\n",
        "interpreter.set_tensor(input_details[0][\"index\"], attention_mask)\n",
        "interpreter.set_tensor(input_details[1][\"index\"], input_ids)\n",
        "\n",
        "# Chạy mô hình\n",
        "interpreter.invoke()\n",
        "\n",
        "# Lấy kết quả đầu ra & giải lượng tử hóa\n",
        "output_scale, output_zero_point = output_details[0]['quantization']\n",
        "output_data_q = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "output_data = (output_data_q.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "print(\"Kết quả đầu ra (logits float32):\", output_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rjTuUlbYFcC"
      },
      "outputs": [],
      "source": [
        "predicted_label = np.argmax(output_data, axis=-1)\n",
        "print(\"Nhãn dự đoán:\", predicted_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0pyaaplZD_j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def get_dir_size(path):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size\n",
        "\n",
        "export_dir = \"saved_model_distilbert/saved_model\"\n",
        "\n",
        "size_mb = get_dir_size(export_dir) / (1024 * 1024)\n",
        "\n",
        "print(f\" Kích thước mô hình gốc: {size_mb:.2f} MB\")\n",
        "print(f\" Kích thước INT8: {os.path.getsize('distilbert_log_classifier_int8.tflite') / (1024 * 1024):.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tObgK0hZH0i"
      },
      "outputs": [],
      "source": [
        "# Load mô hình TFLite đã lượng tử hóa\n",
        "interpreter_int8 = tf.lite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "\n",
        "# Kiểm tra thông tin mô hình\n",
        "print(\"INT8 Model Inputs:\", interpreter_int8.get_input_details())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkI7VUhCWfcO"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(\"saved_model_distilbert/saved_model\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyA2bbmBh7is"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Tệp INT8 tồn tại:\", os.path.exists(\"distilbert_log_classifier_int8.tflite\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfKHdIhphyD0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Load mô hình INT8\n",
        "interpreter_int8 = tflite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "interpreter_int8.allocate_tensors()\n",
        "\n",
        "\n",
        "# Chuẩn bị dữ liệu test (có thể lấy từ logs thực tế)\n",
        "test_input = {\n",
        "    \"attention_mask\": np.ones((1, 128), dtype=np.int32),\n",
        "    \"input_ids\": np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "}\n",
        "\n",
        "def run_inference(interpreter, test_input):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    for i, key in enumerate(test_input.keys()):\n",
        "        interpreter.set_tensor(input_details[i]['index'], test_input[key])\n",
        "\n",
        "    start_time = time.time()\n",
        "    interpreter.invoke()\n",
        "    end_time = time.time()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data, end_time - start_time\n",
        "\n",
        "# Chạy inference và đo thời gian\n",
        "output_int8, time_int8 = run_inference(interpreter_int8, test_input)\n",
        "\n",
        "print(f\"Output INT8: {output_int8}, Time: {time_int8:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbG1vBoBieXb"
      },
      "outputs": [],
      "source": [
        "threshold = 50  # Với INT8, giá trị nằm trong khoảng [-128, 127] nên chọn ngưỡng cao hơn\n",
        "labels_int8 = [log_labels_example[i] for i in range(len(output_int8[0])) if output_int8[0][i] > threshold]\n",
        "\n",
        "\n",
        "\n",
        "print(f\" Cảnh báo INT8: {', '.join(labels_int8) if labels_int8 else 'Không có lỗi'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWi6IrO_Dljl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "logs_df = pd.read_csv(\"/content/labeled_logs.csv\")\n",
        "print(\"Các cột trong CSV:\", logs_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmaPyny0a4Yh"
      },
      "outputs": [],
      "source": [
        "print(logs_df[\"logs\"].head())\n",
        "print(logs_df[\"logs\"].dtype)  # Kiểm tra kiểu dữ liệu của cột logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK1aHTVdCrdu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.lite as tflite\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# ======== BƯỚC 1: Load file logs.csv ========\n",
        "log_file = \"/content/labeled_logs.csv\"\n",
        "try:\n",
        "    logs_df = pd.read_csv(log_file)\n",
        "    assert \"logs\" in logs_df.columns, \" Cột 'logs' không tồn tại trong file CSV!\"\n",
        "\n",
        "    # Chuyển tất cả giá trị về chuỗi, thay NaN bằng chuỗi rỗng\n",
        "    logs_df[\"logs\"] = logs_df[\"logs\"].fillna(\"\").astype(str)\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\" Lỗi khi đọc file CSV: {e}\")\n",
        "\n",
        "# ======== BƯỚC 2: Tokenizer thật ========\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_log(log_message):\n",
        "    try:\n",
        "        tokens = tokenizer(\n",
        "            log_message, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"np\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": tokens[\"input_ids\"].astype(np.int32),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].astype(np.int32)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tokenize log: {log_message} → {e}\")\n",
        "        return {\n",
        "            \"input_ids\": np.zeros((1, 128), dtype=np.int32),\n",
        "            \"attention_mask\": np.zeros((1, 128), dtype=np.int32)\n",
        "        }\n",
        "\n",
        "logs_data = [tokenize_log(msg) for msg in logs_df[\"logs\"]]\n",
        "\n",
        "# ======== BƯỚC 3: Load mô hình INT8 ========\n",
        "try:\n",
        "    interpreter_int8 = tflite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "\n",
        "\n",
        "    interpreter_int8.allocate_tensors()\n",
        "\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\" Lỗi khi load mô hình: {e}\")\n",
        "\n",
        "# ======== BƯỚC 4: Mapping số nhãn → nội dung cảnh báo ========\n",
        "log_labels_mapping = {\n",
        "    0: \"ERROR - MPD problem\", 1: \"ERROR - control amplifier\",\n",
        "    2: \"ERROR - delete message\", 3: \"ERROR - download message\",\n",
        "    4: \"ERROR - invalid checksum\", 5: \"ERROR - invalid message size\",\n",
        "    6: \"ERROR - message download\", 7: \"ERROR - start MPD failed\",\n",
        "    8: \"ERROR: config SIM, GSM error\", 9: \"NOTE - all threads closed\",\n",
        "    10: \"NOTE - speaker changes state from Off to On\",\n",
        "    11: \"NOTE - speaker changes state from On to Off\",\n",
        "    12: \"Normal\",\n",
        "    13: \"Note - message played done\", 14: \"UNKNOWN LOG\", 15: \"WARNING - On disconnect\"\n",
        "}\n",
        "\n",
        "# ======== BƯỚC 5: Chạy inference ========\n",
        "def run_inference(interpreter, log_data):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], log_data[\"input_ids\"])\n",
        "    interpreter.set_tensor(input_details[1]['index'], log_data[\"attention_mask\"])\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data\n",
        "\n",
        "for i, log_data in enumerate(logs_data):\n",
        "    output_int8 = run_inference(interpreter_int8, log_data)\n",
        "\n",
        "    predicted_label_int8 = np.argmax(output_int8)\n",
        "\n",
        "    # Tránh lỗi KeyError khi tra cứu nhãn\n",
        "    label_int8 = log_labels_mapping.get(predicted_label_int8, \"Unknown label\")\n",
        "\n",
        "    print(f\"Log {i+1}: {logs_df['logs'][i]}\")\n",
        "    print(f\"  - INT8 Prediction: {label_int8}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}